// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.9
// 	protoc        v3.21.12
// source: internal/proto/ai_service.proto

package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request para generar contenido
type GenerateRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Prompt        string                 `protobuf:"bytes,1,opt,name=prompt,proto3" json:"prompt,omitempty"`
	SystemPrompt  string                 `protobuf:"bytes,2,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"` // Original
	System        string                 `protobuf:"bytes,7,opt,name=system,proto3" json:"system,omitempty"`                                 // Alias para system_prompt
	Model         string                 `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	Provider      string                 `protobuf:"bytes,4,opt,name=provider,proto3" json:"provider,omitempty"`
	MaxTokens     int32                  `protobuf:"varint,5,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	Temperature   float32                `protobuf:"fixed32,6,opt,name=temperature,proto3" json:"temperature,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateRequest) Reset() {
	*x = GenerateRequest{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateRequest) ProtoMessage() {}

func (x *GenerateRequest) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateRequest.ProtoReflect.Descriptor instead.
func (*GenerateRequest) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{0}
}

func (x *GenerateRequest) GetPrompt() string {
	if x != nil {
		return x.Prompt
	}
	return ""
}

func (x *GenerateRequest) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *GenerateRequest) GetSystem() string {
	if x != nil {
		return x.System
	}
	return ""
}

func (x *GenerateRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *GenerateRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *GenerateRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *GenerateRequest) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

// Response de generaci√≥n
type GenerateResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	Model         string                 `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	Provider      string                 `protobuf:"bytes,3,opt,name=provider,proto3" json:"provider,omitempty"`
	TokensUsed    int32                  `protobuf:"varint,4,opt,name=tokens_used,json=tokensUsed,proto3" json:"tokens_used,omitempty"`
	Duration      int64                  `protobuf:"varint,5,opt,name=duration,proto3" json:"duration,omitempty"`
	Metadata      map[string]string      `protobuf:"bytes,6,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateResponse) Reset() {
	*x = GenerateResponse{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateResponse) ProtoMessage() {}

func (x *GenerateResponse) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateResponse.ProtoReflect.Descriptor instead.
func (*GenerateResponse) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{1}
}

func (x *GenerateResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *GenerateResponse) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *GenerateResponse) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *GenerateResponse) GetTokensUsed() int32 {
	if x != nil {
		return x.TokensUsed
	}
	return 0
}

func (x *GenerateResponse) GetDuration() int64 {
	if x != nil {
		return x.Duration
	}
	return 0
}

func (x *GenerateResponse) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Chunk de streaming
type StreamChunk struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	Index         int32                  `protobuf:"varint,2,opt,name=index,proto3" json:"index,omitempty"`
	Finished      bool                   `protobuf:"varint,3,opt,name=finished,proto3" json:"finished,omitempty"`
	Timestamp     int64                  `protobuf:"varint,4,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamChunk) Reset() {
	*x = StreamChunk{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamChunk) ProtoMessage() {}

func (x *StreamChunk) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamChunk.ProtoReflect.Descriptor instead.
func (*StreamChunk) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{2}
}

func (x *StreamChunk) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *StreamChunk) GetIndex() int32 {
	if x != nil {
		return x.Index
	}
	return 0
}

func (x *StreamChunk) GetFinished() bool {
	if x != nil {
		return x.Finished
	}
	return false
}

func (x *StreamChunk) GetTimestamp() int64 {
	if x != nil {
		return x.Timestamp
	}
	return 0
}

// Request para listar modelos
type ListModelsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{3}
}

// Response con lista de modelos
type ListModelsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*Model               `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{4}
}

func (x *ListModelsResponse) GetModels() []*Model {
	if x != nil {
		return x.Models
	}
	return nil
}

// Modelo de IA
type Model struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Name          string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	Provider      string                 `protobuf:"bytes,3,opt,name=provider,proto3" json:"provider,omitempty"`
	MaxTokens     int32                  `protobuf:"varint,4,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	Description   string                 `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	Capabilities  []string               `protobuf:"bytes,6,rep,name=capabilities,proto3" json:"capabilities,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Model) Reset() {
	*x = Model{}
	mi := &file_internal_proto_ai_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Model) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Model) ProtoMessage() {}

func (x *Model) ProtoReflect() protoreflect.Message {
	mi := &file_internal_proto_ai_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Model.ProtoReflect.Descriptor instead.
func (*Model) Descriptor() ([]byte, []int) {
	return file_internal_proto_ai_service_proto_rawDescGZIP(), []int{5}
}

func (x *Model) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *Model) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Model) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *Model) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *Model) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Model) GetCapabilities() []string {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

var File_internal_proto_ai_service_proto protoreflect.FileDescriptor

const file_internal_proto_ai_service_proto_rawDesc = "" +
	"\n" +
	"\x1finternal/proto/ai_service.proto\x12\x05proto\"\xd9\x01\n" +
	"\x0fGenerateRequest\x12\x16\n" +
	"\x06prompt\x18\x01 \x01(\tR\x06prompt\x12#\n" +
	"\rsystem_prompt\x18\x02 \x01(\tR\fsystemPrompt\x12\x16\n" +
	"\x06system\x18\a \x01(\tR\x06system\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x12\x1a\n" +
	"\bprovider\x18\x04 \x01(\tR\bprovider\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x05 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vtemperature\x18\x06 \x01(\x02R\vtemperature\"\x9b\x02\n" +
	"\x10GenerateResponse\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12\x1a\n" +
	"\bprovider\x18\x03 \x01(\tR\bprovider\x12\x1f\n" +
	"\vtokens_used\x18\x04 \x01(\x05R\n" +
	"tokensUsed\x12\x1a\n" +
	"\bduration\x18\x05 \x01(\x03R\bduration\x12A\n" +
	"\bmetadata\x18\x06 \x03(\v2%.proto.GenerateResponse.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"w\n" +
	"\vStreamChunk\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x12\x14\n" +
	"\x05index\x18\x02 \x01(\x05R\x05index\x12\x1a\n" +
	"\bfinished\x18\x03 \x01(\bR\bfinished\x12\x1c\n" +
	"\ttimestamp\x18\x04 \x01(\x03R\ttimestamp\"\x13\n" +
	"\x11ListModelsRequest\":\n" +
	"\x12ListModelsResponse\x12$\n" +
	"\x06models\x18\x01 \x03(\v2\f.proto.ModelR\x06models\"\xac\x01\n" +
	"\x05Model\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12\x1a\n" +
	"\bprovider\x18\x03 \x01(\tR\bprovider\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x04 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12\"\n" +
	"\fcapabilities\x18\x06 \x03(\tR\fcapabilities2\xcb\x01\n" +
	"\tAIService\x12;\n" +
	"\bGenerate\x12\x16.proto.GenerateRequest\x1a\x17.proto.GenerateResponse\x12>\n" +
	"\x0eGenerateStream\x12\x16.proto.GenerateRequest\x1a\x12.proto.StreamChunk0\x01\x12A\n" +
	"\n" +
	"ListModels\x12\x18.proto.ListModelsRequest\x1a\x19.proto.ListModelsResponseB=Z;github.com/proyectoskevinsvega/mcp-server-ai/internal/protob\x06proto3"

var (
	file_internal_proto_ai_service_proto_rawDescOnce sync.Once
	file_internal_proto_ai_service_proto_rawDescData []byte
)

func file_internal_proto_ai_service_proto_rawDescGZIP() []byte {
	file_internal_proto_ai_service_proto_rawDescOnce.Do(func() {
		file_internal_proto_ai_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_internal_proto_ai_service_proto_rawDesc), len(file_internal_proto_ai_service_proto_rawDesc)))
	})
	return file_internal_proto_ai_service_proto_rawDescData
}

var file_internal_proto_ai_service_proto_msgTypes = make([]protoimpl.MessageInfo, 7)
var file_internal_proto_ai_service_proto_goTypes = []any{
	(*GenerateRequest)(nil),    // 0: proto.GenerateRequest
	(*GenerateResponse)(nil),   // 1: proto.GenerateResponse
	(*StreamChunk)(nil),        // 2: proto.StreamChunk
	(*ListModelsRequest)(nil),  // 3: proto.ListModelsRequest
	(*ListModelsResponse)(nil), // 4: proto.ListModelsResponse
	(*Model)(nil),              // 5: proto.Model
	nil,                        // 6: proto.GenerateResponse.MetadataEntry
}
var file_internal_proto_ai_service_proto_depIdxs = []int32{
	6, // 0: proto.GenerateResponse.metadata:type_name -> proto.GenerateResponse.MetadataEntry
	5, // 1: proto.ListModelsResponse.models:type_name -> proto.Model
	0, // 2: proto.AIService.Generate:input_type -> proto.GenerateRequest
	0, // 3: proto.AIService.GenerateStream:input_type -> proto.GenerateRequest
	3, // 4: proto.AIService.ListModels:input_type -> proto.ListModelsRequest
	1, // 5: proto.AIService.Generate:output_type -> proto.GenerateResponse
	2, // 6: proto.AIService.GenerateStream:output_type -> proto.StreamChunk
	4, // 7: proto.AIService.ListModels:output_type -> proto.ListModelsResponse
	5, // [5:8] is the sub-list for method output_type
	2, // [2:5] is the sub-list for method input_type
	2, // [2:2] is the sub-list for extension type_name
	2, // [2:2] is the sub-list for extension extendee
	0, // [0:2] is the sub-list for field type_name
}

func init() { file_internal_proto_ai_service_proto_init() }
func file_internal_proto_ai_service_proto_init() {
	if File_internal_proto_ai_service_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_internal_proto_ai_service_proto_rawDesc), len(file_internal_proto_ai_service_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   7,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_internal_proto_ai_service_proto_goTypes,
		DependencyIndexes: file_internal_proto_ai_service_proto_depIdxs,
		MessageInfos:      file_internal_proto_ai_service_proto_msgTypes,
	}.Build()
	File_internal_proto_ai_service_proto = out.File
	file_internal_proto_ai_service_proto_goTypes = nil
	file_internal_proto_ai_service_proto_depIdxs = nil
}
